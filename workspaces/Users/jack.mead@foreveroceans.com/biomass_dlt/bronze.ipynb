{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78840603-ea9a-4ef8-96d5-e1f4af1ba998",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "import json\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "\n",
    "kafka_brokers = spark.conf.get('spark.custom.bronze.kafka_brokers')\n",
    "consume_topic = spark.conf.get('spark.custom.bronze.consume_topic')\n",
    "table_name = spark.conf.get('spark.custom.bronze.table_name')\n",
    "table_path = spark.conf.get('spark.custom.bronze.table_path')\n",
    "\n",
    "data_schema = \"\"\"\n",
    "{\"fields\":[{\"metadata\":{},\"name\":\"schemaVersion\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{},\"name\":\"cameraName\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{},\"name\":\"fileUrl\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{},\"name\":\"uniqueKey\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{},\"name\":\"modelVersion\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{},\"name\":\"instanceIndex\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"timestamp\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"poseCheck\",\"nullable\":true,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"depthCheck\",\"nullable\":true,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"boundingBox\",\"nullable\":true,\"type\":{\"containsNull\":true,\"elementType\":\"integer\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"maskSize\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"depthSize\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"pixelLength\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"stdDepth\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"nosePoint\",\"nullable\":true,\"type\":{\"containsNull\":true,\"elementType\":\"double\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"noseDepth\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"tailPoint\",\"nullable\":true,\"type\":{\"containsNull\":true,\"elementType\":\"double\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"tailDepth\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"avgDepth\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"length3d\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"biomass\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"minDepth\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"maxDepth\",\"nullable\":true,\"type\":\"double\"}],\"type\":\"struct\"}\n",
    "\"\"\"\n",
    "data_schema = StructType.fromJson(json.loads(data_schema))\n",
    "\n",
    "event_schema = StructType([\n",
    "    StructField(\"data\", data_schema, False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0fe4365-b4eb-465e-8112-e2d2c52d6599",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=table_name,\n",
    "    comment=\"\"\"\n",
    "    Raw Biomass Results\n",
    "\n",
    "    Biomass results for all frames taken from the biocams. This contains all false and true positive\n",
    "    instances. This table may contain duplicates and instances that did not pass certain thresholds\n",
    "    within the models.\n",
    "    \"\"\",\n",
    "    path=table_path,\n",
    "    partition_cols=[\"cameraName\", \"year\", \"month\", \"day\"],\n",
    "    spark_conf={\n",
    "        'spark.sql.session.timeZone': 'UTC'\n",
    "    },\n",
    "    table_properties={\n",
    "        'pipelines.autoOptimize.managed': 'true',\n",
    "        'pipelines.autoOptimize.zOrderCols': 'timestamp',\n",
    "        'pipelines.reset.allowed': 'false'\n",
    "    }\n",
    ")\n",
    "def bronze_data():\n",
    "    df = spark \\\n",
    "        .readStream \\\n",
    "        .format('kafka') \\\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_brokers)\\\n",
    "        .option(\"subscribe\", consume_topic)\\\n",
    "        .option(\"startingOffsets\", \"earliest\")\\\n",
    "        .option(\"failOnDataLoss\", \"false\")\\\n",
    "        .load()\n",
    "    \n",
    "    df = df\\\n",
    "        .selectExpr(\n",
    "            \"CAST(value AS STRING)\"\n",
    "        )\\\n",
    "        .withColumn(\n",
    "            'value', f.from_json(f.col('value'), event_schema)\n",
    "        )\\\n",
    "        .select('value.*')\\\n",
    "        .select('data.*')\n",
    "    \n",
    "    df = df.withColumn('date', f.to_timestamp(f.from_unixtime(f.col('timestamp') / 1000, 'yyyy-MM-dd')))\n",
    "    df = df.withColumn('year', f.year('date'))\n",
    "    df = df.withColumn('month', f.month('date'))\n",
    "    df = df.withColumn('day', f.dayofmonth('date'))\n",
    "    df = df.drop('date')\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
