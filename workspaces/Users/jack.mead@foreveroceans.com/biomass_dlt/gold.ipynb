{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6007da42-a389-4de3-84f4-1c8e52f3163f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "import json\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "\n",
    "silver_table_name = spark.conf.get('spark.custom.gold.silver_table_name')\n",
    "table_name = spark.conf.get('spark.custom.gold.table_name')\n",
    "table_path = spark.conf.get('spark.custom.gold.table_path')\n",
    "watermark = spark.conf.get('spark.custom.gold.watermark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c702c60-2b18-473f-aa4c-7465bee6013e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=table_name,\n",
    "    comment=\"\"\"\n",
    "    Daily AI Biomass Aggregations\n",
    "\n",
    "    This dataset contains daily aggregations produced from the biomass_filtered table.\n",
    "    \"\"\",\n",
    "    path=table_path,\n",
    "    partition_cols=[\"camera_name\", \"year\", \"month\", \"day\"],\n",
    "    spark_conf={\n",
    "        'spark.sql.sources.partitionOverwriteMode': 'dynamic',\n",
    "        'spark.sql.session.timeZone': 'UTC'\n",
    "    },\n",
    "    table_properties={\n",
    "        'pipelines.autoOptimize.managed': 'true',\n",
    "        'pipelines.autoOptimize.zOrderCols': 'model_version'\n",
    "    }\n",
    ")\n",
    "def gold_data():\n",
    "    df = spark\\\n",
    "        .read\\\n",
    "        .format('delta')\\\n",
    "        .table(silver_table_name)\n",
    "    \n",
    "    df = df.withColumn('date', f.to_date(f.col('timestamp')))\n",
    "    df = df.filter(f'date >= date_sub(current_date(), {watermark})')\n",
    "\n",
    "    df = df\\\n",
    "        .groupBy(\n",
    "            f.col('camera_name'),\n",
    "            f.col('model_version'),\n",
    "            f.window('timestamp', '1 day')\n",
    "        )\\\n",
    "        .agg(\n",
    "            f.count_distinct('unique_key').alias('instances_detected'),\n",
    "    \n",
    "            f.percentile_approx('offset_weight', 0.5).alias('median_offset_weight'),\n",
    "            f.stddev('offset_weight').alias('std_offset_weight'),\n",
    "            f.mean('offset_weight').alias('avg_offset_weight'),\n",
    "            f.min('offset_weight').alias('min_offset_weight'),\n",
    "            f.max('offset_weight').alias('max_offset_weight'),\n",
    "        \n",
    "            f.percentile_approx('weight', 0.5).alias('median_weight'),\n",
    "            f.stddev('weight').alias('std_weight'),\n",
    "            f.mean('weight').alias('avg_weight'),\n",
    "            f.min('weight').alias('min_weight'),\n",
    "            f.max('weight').alias('max_weight'),\n",
    "        \n",
    "            f.percentile_approx('avg_depth', 0.5).alias('median_depth'),\n",
    "            f.stddev('avg_depth').alias('std_depth'),\n",
    "            f.mean('avg_depth').alias('avg_depth'),\n",
    "            f.min('avg_depth').alias('min_depth'),\n",
    "            f.max('avg_depth').alias('max_depth'),\n",
    "        \n",
    "            f.percentile_approx('length', 0.5).alias('median_length'),\n",
    "            f.stddev('length').alias('std_length'),\n",
    "            f.mean('length').alias('avg_length'),\n",
    "            f.min('length').alias('min_length'),\n",
    "            f.max('length').alias('max_length'),\n",
    "        \n",
    "            f.percentile_approx('offset_length', 0.5).alias('median_offset_length'),\n",
    "            f.stddev('offset_length').alias('std_offset_length'),\n",
    "            f.mean('offset_length').alias('avg_offset_length'),\n",
    "            f.min('offset_length').alias('min_offset_length'),\n",
    "            f.max('offset_length').alias('max_offset_length'),\n",
    "        )\n",
    "    \n",
    "    df = df\\\n",
    "        .withColumn('year', f.year('window.start'))\\\n",
    "        .withColumn('month', f.month('window.start'))\\\n",
    "        .withColumn('day', f.dayofmonth('window.start'))\\\n",
    "        .withColumn('date', f.to_date(f.col('window.start')))\\\n",
    "        .drop('window')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1448178866816446,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gold",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
